{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18408\n",
      "content Comment: lets not forget that apple pay in 2014 required a brand new iphone in order to use it a significant portion of apples user base wasnt able to use it even if they wanted to as each successive iphone incorporated the technology and older iphones were replaced the number of people who could use the technology increased\n",
      "Sentiment: neutral and metdata {'source': './data/YoutubeCommentsDataSet.csv', 'row': 0}\n",
      "\n",
      "content Comment: here in nz 50 of retailers don’t even have contactless credit card machines like paywave which support apple pay they don’t like the high fees that come with these\n",
      "Sentiment: negative and metdata {'source': './data/YoutubeCommentsDataSet.csv', 'row': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import CSVLoader, PyMuPDFLoader\n",
    "\n",
    "# Load data from a CSV file using CSVLoader\n",
    "loader = CSVLoader(\"./data/YoutubeCommentsDataSet.csv\")\n",
    "documents = loader.load()\n",
    "print(len(documents))\n",
    "# Access the content and metadata of each document\n",
    "for document in documents[:2]:    \n",
    "\tcontent = document.page_content    \n",
    "\tmetadata = document.metadata\n",
    "\tprint(f'content {content} and metdata {metadata}\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"What is the capital of France?\"\n",
    "    ),\n",
    "]\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents embedded: 5\n",
      "Document Hi there! and it sembedding is [-0.020325319841504097, -0.007096723187714815, -0.022839006036520004, -0.026279456913471222, -0.037527572363615036, 0.02163294516503811, -0.006144568789750338, -0.008975640870630741, 0.008524954319000244, -0.016618264839053154, 0.02683805488049984, -0.007356978487223387, -0.013545980677008629, -0.024133935570716858, 0.006512735038995743, -0.020198365673422813, 0.02426088973879814, -0.014739347621798515, 0.016427835449576378, -0.01647861674427986, -0.007204633671790361, -0.008080615662038326, 0.004694120492786169, -0.002066174754872918, -0.014802824705839157]\n",
      "Dimension of each embedding: 1536\n"
     ]
    }
   ],
   "source": [
    "#from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "# Initialize the model\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "# Embed a list of texts\n",
    "docs = [\"Hi there!\", \"Oh, hello!\", \"What's your name?\", \"My friends call me World\", \"Hello World!\"]\n",
    "embeddings = embeddings_model.embed_documents(docs, chunk_size=20)\n",
    "\n",
    "print(\"Number of documents embedded:\", len(embeddings))\n",
    "print(f'Document {docs[0]} and it sembedding is {embeddings[0][:25]}')\n",
    "print(\"Dimension of each embedding:\", len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
